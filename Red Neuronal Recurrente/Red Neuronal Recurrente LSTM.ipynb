{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal recurrente LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Reiniciamos todas las variables.\n",
    "%reset\n",
    "\n",
    "# Importamos las librerias necesarias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Importamos el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En las siguientes celdas formalizaremos los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "186\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Creamos el DataFrame con los datos de los archivos .csv para el entrenamiento.\n",
    "# Para entrenar con diez años de datos.\n",
    "# Historico = pd.read_csv('GAS.MC.Entrenamiento(2007-2016).csv')\n",
    "\n",
    "# Para entrenar con dos años de datos.\n",
    "# Historico = pd.read_csv('GAS.MC.Entrenamiento(2015-2016).csv')\n",
    "\n",
    "# Para entrenar con un año de datos.\n",
    "Historico = pd.read_csv('GAS.MC.Entrenamiento(2016).csv')\n",
    "\n",
    "# Guardamos en variables los valores de la fecha(Date) y el precio de cierre de (Close).\n",
    "Close = Historico['Close']\n",
    "Date = Historico['Date']\n",
    "\n",
    "# Pasamos el dataset a tipo float porque es más adecuado en el manejo de redes neuronales, aunque el dataset que usamos ya\n",
    "# está en valores de tipo float, es bueno mantener esta línea por si probasemos nuevos datasets con valores de tipo entero.\n",
    "Close = Close.astype(float)\n",
    "\n",
    "# Varible que define nuestro intervalo para estudiar predicciones (En nuestro caso tomamos el valor 20 porque es el intervalo\n",
    "# entre meses de los cierres de la empresa).\n",
    "periodo = 20\n",
    "\n",
    "# Cogemos el 80 % de los datos para el entrenamiento.\n",
    "NumDatosEntrenamiento = round(len(Close) * 0.8) - periodo\n",
    "# Cogemos el restante del dataset\n",
    "NumDatosEvaluate = round(len(Close) * 0.2) - periodo\n",
    "# En ambos dataset les restamos el periodo ya que los últimos valores del dataset no tienen salida ya que son mínimamente \n",
    "# necesarios 20 valores (en nuestro caso 20 por el periodo que escogimos) para poder conocer una salida. Por ejemplo para que\n",
    "# el último valor de nuestro dataset tuviera salida deberíamos conocer los siguientes 20 valores.\n",
    "\n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(len(Close))\n",
    "print(NumDatosEntrenamiento)\n",
    "print(NumDatosEvaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos de Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.424999 18.65     18.51     ... 17.74     17.83     18.014999]\n",
      " [18.65     18.51     18.344999 ... 17.83     18.014999 18.135   ]\n",
      " [18.51     18.344999 17.735001 ... 18.014999 18.135    17.799999]\n",
      " ...\n",
      " [18.174999 18.040001 17.965    ... 17.495001 17.49     17.84    ]\n",
      " [18.040001 17.965    18.1      ... 17.49     17.84     17.73    ]\n",
      " [17.965    18.1      17.950001 ... 17.84     17.73     17.85    ]]\n",
      "(186, 20)\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos la matriz. \n",
    "# Tendrá el número de filas de tamaño NumDatosEntrenamiento.\n",
    "# Tendrá el número de columnas de tamaño periodo ya que nos interesa que representen un intervalo de 20 días, estos días van a \n",
    "# ser los parámetros de nuestra red que generaran una salida (el día siguiente).\n",
    "matrizDatosEntrenamiento = np.zeros((NumDatosEntrenamiento, periodo))\n",
    "\n",
    "# Inicializamos la variable aux, lo interesante de esta variable es que nos permitirá movernos por el dataset en intervalos\n",
    "# de valor del periodo.\n",
    "aux = 0\n",
    "\n",
    "# Creamos nuestra matriz de datos de entrada.\n",
    "# Este for sirve crear nuestra matriz de datos de entrenamiento.\n",
    "# Con el primer for recorremos las filas del dataset.\n",
    "for i in range (0, NumDatosEntrenamiento):\n",
    "    \n",
    "    # Inicializamos la variable contador que nos servirá para movernos por las columnas de la matriz.\n",
    "    cont = 0\n",
    "    # En este bucle nos movemos en intervalos de 20 a través del dataset.\n",
    "    for j in range (0, periodo):\n",
    "        \n",
    "        # Guardamos los valores de los cierres en las matriz de entrenamiento.\n",
    "        matrizDatosEntrenamiento[i][cont] = np.array(Close[j + aux])\n",
    "        # Como podemos ver, cuando aux aumente de valor los intervalos por los que nos movemos aumentarán, es decir en nuestro\n",
    "        # caso el primer intervalo es [0 - 20], el segundo será [1 - 21] y el tercero [2 - 32] y etc...\n",
    "        cont = cont + 1\n",
    "   \n",
    "\n",
    "    aux = aux + 1\n",
    "    \n",
    "# Para explicarnos mejor lo que hacemos aqui proponemos un ejemplo.\n",
    "# Imaginemos que tenemos 21 valores de cierres de una empresa.\n",
    "# nuestros parámetros van a ser los valores de los veinte primeros días y la salida generada sería el valor del día 21.\n",
    "# En el bucle anterior estamos creando nuestra matriz de entrenamiento en la que cada fila guarda intervalos de 20 días, es \n",
    "# decir, fila 0 guardará los datos de 0-20, fila 1 los datos de 1-21, etc... hasta terminar con todo el dataset.\n",
    "\n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(matrizDatosEntrenamiento)\n",
    "print(matrizDatosEntrenamiento.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos de Salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.135   ]\n",
      " [17.799999]\n",
      " [16.82    ]\n",
      " [16.5     ]\n",
      " [16.495001]\n",
      " [15.96    ]\n",
      " [15.555   ]\n",
      " [15.595   ]\n",
      " [15.14    ]\n",
      " [15.265   ]\n",
      " [15.79    ]\n",
      " [15.665   ]\n",
      " [15.805   ]\n",
      " [16.315001]\n",
      " [16.1     ]\n",
      " [16.344999]\n",
      " [16.07    ]\n",
      " [15.62    ]\n",
      " [15.705   ]\n",
      " [16.065001]\n",
      " [16.125   ]\n",
      " [16.254999]\n",
      " [16.379999]\n",
      " [16.610001]\n",
      " [16.715   ]\n",
      " [16.530001]\n",
      " [16.485001]\n",
      " [16.655001]\n",
      " [16.635   ]\n",
      " [17.200001]\n",
      " [17.264999]\n",
      " [17.059999]\n",
      " [16.995001]\n",
      " [17.15    ]\n",
      " [17.295   ]\n",
      " [17.584999]\n",
      " [17.68    ]\n",
      " [17.775   ]\n",
      " [17.785   ]\n",
      " [17.924999]\n",
      " [17.93    ]\n",
      " [17.77    ]\n",
      " [17.35    ]\n",
      " [17.35    ]\n",
      " [17.145   ]\n",
      " [17.195   ]\n",
      " [16.924999]\n",
      " [17.23    ]\n",
      " [17.469999]\n",
      " [17.615   ]\n",
      " [17.725   ]\n",
      " [17.695   ]\n",
      " [17.48    ]\n",
      " [17.575001]\n",
      " [18.      ]\n",
      " [18.215   ]\n",
      " [18.195   ]\n",
      " [18.305   ]\n",
      " [18.305   ]\n",
      " [18.514999]\n",
      " [18.445   ]\n",
      " [18.549999]\n",
      " [18.165001]\n",
      " [18.16    ]\n",
      " [17.735001]\n",
      " [17.424999]\n",
      " [17.5     ]\n",
      " [17.67    ]\n",
      " [17.805   ]\n",
      " [17.82    ]\n",
      " [16.834999]\n",
      " [16.915001]\n",
      " [16.965   ]\n",
      " [16.92    ]\n",
      " [17.01    ]\n",
      " [17.110001]\n",
      " [16.92    ]\n",
      " [17.055   ]\n",
      " [17.135   ]\n",
      " [17.365   ]\n",
      " [17.58    ]\n",
      " [17.700001]\n",
      " [17.84    ]\n",
      " [17.915001]\n",
      " [17.790001]\n",
      " [17.389999]\n",
      " [17.440001]\n",
      " [17.360001]\n",
      " [17.584999]\n",
      " [18.035   ]\n",
      " [17.959999]\n",
      " [18.030001]\n",
      " [17.565001]\n",
      " [17.275   ]\n",
      " [16.965   ]\n",
      " [17.004999]\n",
      " [16.934999]\n",
      " [17.24    ]\n",
      " [17.764999]\n",
      " [17.584999]\n",
      " [17.514999]\n",
      " [17.655001]\n",
      " [16.01    ]\n",
      " [15.76    ]\n",
      " [16.299999]\n",
      " [17.094999]\n",
      " [17.665001]\n",
      " [17.715   ]\n",
      " [17.795   ]\n",
      " [17.469999]\n",
      " [17.26    ]\n",
      " [17.790001]\n",
      " [17.809999]\n",
      " [17.924999]\n",
      " [17.799999]\n",
      " [18.040001]\n",
      " [18.084999]\n",
      " [17.915001]\n",
      " [17.860001]\n",
      " [17.895   ]\n",
      " [18.129999]\n",
      " [18.1     ]\n",
      " [18.145   ]\n",
      " [18.15    ]\n",
      " [18.334999]\n",
      " [18.424999]\n",
      " [18.559999]\n",
      " [18.504999]\n",
      " [18.395   ]\n",
      " [18.02    ]\n",
      " [18.059999]\n",
      " [18.254999]\n",
      " [18.41    ]\n",
      " [18.4     ]\n",
      " [18.559999]\n",
      " [18.575001]\n",
      " [18.879999]\n",
      " [18.799999]\n",
      " [18.885   ]\n",
      " [18.615   ]\n",
      " [18.33    ]\n",
      " [18.5     ]\n",
      " [18.285   ]\n",
      " [18.120001]\n",
      " [18.405001]\n",
      " [18.370001]\n",
      " [18.344999]\n",
      " [18.5     ]\n",
      " [18.365   ]\n",
      " [18.465   ]\n",
      " [18.504999]\n",
      " [19.07    ]\n",
      " [19.495001]\n",
      " [19.655001]\n",
      " [19.315001]\n",
      " [19.16    ]\n",
      " [19.225   ]\n",
      " [18.955   ]\n",
      " [18.51    ]\n",
      " [18.165001]\n",
      " [18.334999]\n",
      " [18.285   ]\n",
      " [17.959999]\n",
      " [18.174999]\n",
      " [18.040001]\n",
      " [17.965   ]\n",
      " [18.1     ]\n",
      " [17.950001]\n",
      " [17.905001]\n",
      " [17.955   ]\n",
      " [18.040001]\n",
      " [18.27    ]\n",
      " [18.295   ]\n",
      " [18.18    ]\n",
      " [18.135   ]\n",
      " [17.945   ]\n",
      " [17.725   ]\n",
      " [17.57    ]\n",
      " [17.855   ]\n",
      " [17.540001]\n",
      " [17.495001]\n",
      " [17.49    ]\n",
      " [17.84    ]\n",
      " [17.73    ]\n",
      " [17.85    ]\n",
      " [17.895   ]]\n",
      "(186, 1)\n"
     ]
    }
   ],
   "source": [
    "# Inizializamos el vector.\n",
    "Salida = np.zeros(NumDatosEntrenamiento)\n",
    "\n",
    "# Inicializamos una variable con el valor de nuestro periodo que usaremos más adelante.\n",
    "aux = periodo\n",
    "\n",
    "# En este bucle guardamos en el vector Salida los valores de Close que representan nuestra salida deseada para la matriz de \n",
    "# entrenamiento.\n",
    "for i in range (0, NumDatosEntrenamiento):\n",
    "    # Debemos empezar a guardar desde la posición del valor aux ya que es donde se guarda la primera salida deseada de nuestro \n",
    "    # primer ejemplo de entrenamiento.\n",
    "    Salida[i] = Close[aux]\n",
    "    aux = aux +1   \n",
    "\n",
    "# Convertimos Salida a un DataFrame. Esto lo hacemos para poder usar la ventaja de las funciones de pandas como .iloc.\n",
    "Salida = pd.DataFrame(Salida) \n",
    "\n",
    "# Con este bucle creamos nuestra matriz de salidas de entrenamiento.\n",
    "for i in range(0, len(Salida)) :\n",
    "\n",
    "    if(i == 0) :\n",
    "        salidaEntrenamiento = np.array([Salida.iloc[i, :]]) \n",
    "    else :\n",
    "        salida1 = np.array([Salida.iloc[i, :]])    \n",
    "        salidaEntrenamiento = np.concatenate((salidaEntrenamiento, salida1), axis = 0)\n",
    "\n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(salidaEntrenamiento)\n",
    "print(salidaEntrenamiento.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La entrada de las redes recurrentes debe tener tres dimensiones [num_ejemplos, time_step, parámetros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "matrizDatosEntrenamiento = np.reshape(matrizDatosEntrenamiento, (matrizDatosEntrenamiento.shape[0], 1, periodo))\n",
    "\n",
    "# Para imprimir información adicional.\n",
    "print(matrizDatosEntrenamiento.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos de Entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.       18.004999 17.969999 17.74     18.030001 17.965    17.995001\n",
      "  17.975    17.905001 17.379999 17.135    17.200001 17.200001 17.139999\n",
      "  17.055    16.51     16.360001 16.094999 16.120001 16.27    ]\n",
      " [18.004999 17.969999 17.74     18.030001 17.965    17.995001 17.975\n",
      "  17.905001 17.379999 17.135    17.200001 17.200001 17.139999 17.055\n",
      "  16.51     16.360001 16.094999 16.120001 16.27     16.365   ]\n",
      " [17.969999 17.74     18.030001 17.965    17.995001 17.975    17.905001\n",
      "  17.379999 17.135    17.200001 17.200001 17.139999 17.055    16.51\n",
      "  16.360001 16.094999 16.120001 16.27     16.365    16.145   ]\n",
      " [17.74     18.030001 17.965    17.995001 17.975    17.905001 17.379999\n",
      "  17.135    17.200001 17.200001 17.139999 17.055    16.51     16.360001\n",
      "  16.094999 16.120001 16.27     16.365    16.145    16.205   ]\n",
      " [18.030001 17.965    17.995001 17.975    17.905001 17.379999 17.135\n",
      "  17.200001 17.200001 17.139999 17.055    16.51     16.360001 16.094999\n",
      "  16.120001 16.27     16.365    16.145    16.205    16.375   ]\n",
      " [17.965    17.995001 17.975    17.905001 17.379999 17.135    17.200001\n",
      "  17.200001 17.139999 17.055    16.51     16.360001 16.094999 16.120001\n",
      "  16.27     16.365    16.145    16.205    16.375    16.174999]\n",
      " [17.995001 17.975    17.905001 17.379999 17.135    17.200001 17.200001\n",
      "  17.139999 17.055    16.51     16.360001 16.094999 16.120001 16.27\n",
      "  16.365    16.145    16.205    16.375    16.174999 16.1     ]\n",
      " [17.975    17.905001 17.379999 17.135    17.200001 17.200001 17.139999\n",
      "  17.055    16.51     16.360001 16.094999 16.120001 16.27     16.365\n",
      "  16.145    16.205    16.375    16.174999 16.1      16.32    ]\n",
      " [17.905001 17.379999 17.135    17.200001 17.200001 17.139999 17.055\n",
      "  16.51     16.360001 16.094999 16.120001 16.27     16.365    16.145\n",
      "  16.205    16.375    16.174999 16.1      16.32     16.365   ]\n",
      " [17.379999 17.135    17.200001 17.200001 17.139999 17.055    16.51\n",
      "  16.360001 16.094999 16.120001 16.27     16.365    16.145    16.205\n",
      "  16.375    16.174999 16.1      16.32     16.365    16.280001]\n",
      " [17.135    17.200001 17.200001 17.139999 17.055    16.51     16.360001\n",
      "  16.094999 16.120001 16.27     16.365    16.145    16.205    16.375\n",
      "  16.174999 16.1      16.32     16.365    16.280001 16.15    ]\n",
      " [17.200001 17.200001 17.139999 17.055    16.51     16.360001 16.094999\n",
      "  16.120001 16.27     16.365    16.145    16.205    16.375    16.174999\n",
      "  16.1      16.32     16.365    16.280001 16.15     16.045   ]\n",
      " [17.200001 17.139999 17.055    16.51     16.360001 16.094999 16.120001\n",
      "  16.27     16.365    16.145    16.205    16.375    16.174999 16.1\n",
      "  16.32     16.365    16.280001 16.15     16.045    16.205   ]\n",
      " [17.139999 17.055    16.51     16.360001 16.094999 16.120001 16.27\n",
      "  16.365    16.145    16.205    16.375    16.174999 16.1      16.32\n",
      "  16.365    16.280001 16.15     16.045    16.205    16.139999]\n",
      " [17.055    16.51     16.360001 16.094999 16.120001 16.27     16.365\n",
      "  16.145    16.205    16.375    16.174999 16.1      16.32     16.365\n",
      "  16.280001 16.15     16.045    16.205    16.139999 16.665001]\n",
      " [16.51     16.360001 16.094999 16.120001 16.27     16.365    16.145\n",
      "  16.205    16.375    16.174999 16.1      16.32     16.365    16.280001\n",
      "  16.15     16.045    16.205    16.139999 16.665001 16.514999]\n",
      " [16.360001 16.094999 16.120001 16.27     16.365    16.145    16.205\n",
      "  16.375    16.174999 16.1      16.32     16.365    16.280001 16.15\n",
      "  16.045    16.205    16.139999 16.665001 16.514999 16.51    ]\n",
      " [16.094999 16.120001 16.27     16.365    16.145    16.205    16.375\n",
      "  16.174999 16.1      16.32     16.365    16.280001 16.15     16.045\n",
      "  16.205    16.139999 16.665001 16.514999 16.51     16.715   ]\n",
      " [16.120001 16.27     16.365    16.145    16.205    16.375    16.174999\n",
      "  16.1      16.32     16.365    16.280001 16.15     16.045    16.205\n",
      "  16.139999 16.665001 16.514999 16.51     16.715    16.924999]\n",
      " [16.27     16.365    16.145    16.205    16.375    16.174999 16.1\n",
      "  16.32     16.365    16.280001 16.15     16.045    16.205    16.139999\n",
      "  16.665001 16.514999 16.51     16.715    16.924999 17.129999]\n",
      " [16.365    16.145    16.205    16.375    16.174999 16.1      16.32\n",
      "  16.365    16.280001 16.15     16.045    16.205    16.139999 16.665001\n",
      "  16.514999 16.51     16.715    16.924999 17.129999 17.1     ]\n",
      " [16.145    16.205    16.375    16.174999 16.1      16.32     16.365\n",
      "  16.280001 16.15     16.045    16.205    16.139999 16.665001 16.514999\n",
      "  16.51     16.715    16.924999 17.129999 17.1      17.41    ]\n",
      " [16.205    16.375    16.174999 16.1      16.32     16.365    16.280001\n",
      "  16.15     16.045    16.205    16.139999 16.665001 16.514999 16.51\n",
      "  16.715    16.924999 17.129999 17.1      17.41     17.48    ]\n",
      " [16.375    16.174999 16.1      16.32     16.365    16.280001 16.15\n",
      "  16.045    16.205    16.139999 16.665001 16.514999 16.51     16.715\n",
      "  16.924999 17.129999 17.1      17.41     17.48     17.530001]\n",
      " [16.174999 16.1      16.32     16.365    16.280001 16.15     16.045\n",
      "  16.205    16.139999 16.665001 16.514999 16.51     16.715    16.924999\n",
      "  17.129999 17.1      17.41     17.48     17.530001 17.635   ]\n",
      " [16.1      16.32     16.365    16.280001 16.15     16.045    16.205\n",
      "  16.139999 16.665001 16.514999 16.51     16.715    16.924999 17.129999\n",
      "  17.1      17.41     17.48     17.530001 17.635    17.690001]\n",
      " [16.32     16.365    16.280001 16.15     16.045    16.205    16.139999\n",
      "  16.665001 16.514999 16.51     16.715    16.924999 17.129999 17.1\n",
      "  17.41     17.48     17.530001 17.635    17.690001 17.469999]\n",
      " [16.365    16.280001 16.15     16.045    16.205    16.139999 16.665001\n",
      "  16.514999 16.51     16.715    16.924999 17.129999 17.1      17.41\n",
      "  17.48     17.530001 17.635    17.690001 17.469999 17.594999]\n",
      " [16.280001 16.15     16.045    16.205    16.139999 16.665001 16.514999\n",
      "  16.51     16.715    16.924999 17.129999 17.1      17.41     17.48\n",
      "  17.530001 17.635    17.690001 17.469999 17.594999 17.665001]\n",
      " [16.15     16.045    16.205    16.139999 16.665001 16.514999 16.51\n",
      "  16.715    16.924999 17.129999 17.1      17.41     17.48     17.530001\n",
      "  17.635    17.690001 17.469999 17.594999 17.665001 17.68    ]\n",
      " [16.045    16.205    16.139999 16.665001 16.514999 16.51     16.715\n",
      "  16.924999 17.129999 17.1      17.41     17.48     17.530001 17.635\n",
      "  17.690001 17.469999 17.594999 17.665001 17.68     17.780001]]\n",
      "(31, 20)\n"
     ]
    }
   ],
   "source": [
    "# Realizamos el mismo proceso que la preparación de entradas del conjunto de entrenamiento pero esta vez con el conjunto de \n",
    "# evaluación.\n",
    "\n",
    "# Inicializamos nuestra matriz con ceros de un tamaño correspondiente al resto del dataset no usado (que es el 20 % restante). \n",
    "matrizDatosEvaluate = np.zeros((NumDatosEvaluate, periodo))\n",
    "\n",
    "# Esta variable auxiliar nos servirá para coger la salida correspondiente, en esta caso la inicializamos a la primera posición\n",
    "# de nuestro dataset de evaluate que es la misma posición que nuestro número de ejemplos de entrenamiento más el periodo, le\n",
    "# sumamos el periodo ya que si recordamos al principio le restamos esa cantidad porque eran datos que no servían.\n",
    "aux = NumDatosEntrenamiento + periodo\n",
    "\n",
    "# Este for sirve para crear nuestra matriz de entradas para el evaluate.\n",
    "for i in range (0, NumDatosEvaluate):\n",
    "    \n",
    "    cont = 0\n",
    "    for j in range (0, periodo):\n",
    "            \n",
    "        matrizDatosEvaluate[i][cont] = np.array(Close[j + aux])\n",
    "        cont = cont+1\n",
    "        \n",
    "    aux = aux + 1\n",
    "    \n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(matrizDatosEvaluate)\n",
    "print(matrizDatosEvaluate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos Salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.365   ]\n",
      " [16.145   ]\n",
      " [16.205   ]\n",
      " [16.375   ]\n",
      " [16.174999]\n",
      " [16.1     ]\n",
      " [16.32    ]\n",
      " [16.365   ]\n",
      " [16.280001]\n",
      " [16.15    ]\n",
      " [16.045   ]\n",
      " [16.205   ]\n",
      " [16.139999]\n",
      " [16.665001]\n",
      " [16.514999]\n",
      " [16.51    ]\n",
      " [16.715   ]\n",
      " [16.924999]\n",
      " [17.129999]\n",
      " [17.1     ]\n",
      " [17.41    ]\n",
      " [17.48    ]\n",
      " [17.530001]\n",
      " [17.635   ]\n",
      " [17.690001]\n",
      " [17.469999]\n",
      " [17.594999]\n",
      " [17.665001]\n",
      " [17.68    ]\n",
      " [17.780001]\n",
      " [17.91    ]]\n",
      "(31, 1)\n"
     ]
    }
   ],
   "source": [
    "# Realizamos el mismo proceso que con la preparación de salidas del conjunto de entrenamiento pero esta vez con el conjunto de\n",
    "# evaluación.\n",
    "\n",
    "# Inizializamos el vector de salidas.\n",
    "Salida = np.zeros(NumDatosEvaluate)\n",
    "\n",
    "# Esta variable auxiliar nos servirá para coger la salida correspondiente, en esta caso la inicializamos a la primera posición\n",
    "# de nuestro dataset de evaluate que es la misma posición que nuestro número de ejemplos de entrenamiento más el periodo y a \n",
    "# esta cantidad le sumamos otra vez el periodo. La razon por la que sumamos la primera vez el peridodo es porque si recordamos\n",
    "# al principio le restamos esa cantida a NumDatosEntrenamiento porque eran datos que no servían. La segunda vez que sumamos el\n",
    "# periodo es porque la salida deseada esta una cantidad (de valor periodo) por delante de nuestro primer dato de evaluación. \n",
    "# Ya que se necesita una cantidad (de valor periodo) mínima de datos de evaluación para obtener una salida.\n",
    "aux = (NumDatosEntrenamiento + periodo) + periodo\n",
    "\n",
    "# En este bucle guardamos en el vector Salida los valores de Close que representan nuestra salida deseada para la matriz de \n",
    "# evaluación.\n",
    "for i in range (0, NumDatosEvaluate):\n",
    "\n",
    "    # Debemos empezar a guardar desde la posición del valor aux ya que es donde se guarda la primera salida deseada de nuestro \n",
    "    # primer ejemplo de evaluación.\n",
    "    Salida[i] = Close[aux]\n",
    "    aux = aux + 1\n",
    "\n",
    "# Convertimos Salida a un DataFrame. Esto lo hacemos para poder usar la ventaja de las funciones de pandas como .iloc.\n",
    "Salida = pd.DataFrame(Salida)\n",
    "\n",
    "# Con este bucle creamos nuestra matriz de salidas de entrenamiento.\n",
    "for i in range(0, len(Salida)) :\n",
    "\n",
    "    if(i == 0) :\n",
    "        salidaValidacion = np.array([Salida.iloc[i, :]]) \n",
    "    else :\n",
    "        salida2 = np.array([Salida.iloc[i, :]])    \n",
    "        salidaValidacion = np.concatenate((salidaValidacion, salida2), axis = 0)\n",
    "\n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(salidaValidacion)\n",
    "print(salidaValidacion.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La entrada de las redes recurrentes debe tener tres dimensiones [num_ejemplos, time_step, parámetros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1, 20)\n"
     ]
    }
   ],
   "source": [
    "matrizDatosEvaluate = np.reshape(matrizDatosEvaluate, (matrizDatosEvaluate.shape[0], 1, periodo))\n",
    "\n",
    "# Para imprimir información adicional y comprobar el funcionamiento.\n",
    "print(matrizDatosEvaluate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Construimos la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 194.4492\n",
      "Epoch 2/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 24.6481\n",
      "Epoch 3/200\n",
      "186/186 [==============================] - 0s 342us/step - loss: 13.3447\n",
      "Epoch 4/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 8.0676\n",
      "Epoch 5/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.8994\n",
      "Epoch 6/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 2.6986\n",
      "Epoch 7/200\n",
      "186/186 [==============================] - 0s 457us/step - loss: 1.3991\n",
      "Epoch 8/200\n",
      "186/186 [==============================] - 0s 398us/step - loss: 0.4975\n",
      "Epoch 9/200\n",
      "186/186 [==============================] - 0s 414us/step - loss: 0.8276\n",
      "Epoch 10/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.4810\n",
      "Epoch 11/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.4387\n",
      "Epoch 12/200\n",
      "186/186 [==============================] - 0s 412us/step - loss: 0.4673\n",
      "Epoch 13/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3945\n",
      "Epoch 14/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.4111\n",
      "Epoch 15/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.3935\n",
      "Epoch 16/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.4019\n",
      "Epoch 17/200\n",
      "186/186 [==============================] - 0s 331us/step - loss: 0.3971\n",
      "Epoch 18/200\n",
      "186/186 [==============================] - 0s 487us/step - loss: 0.3909\n",
      "Epoch 19/200\n",
      "186/186 [==============================] - 0s 342us/step - loss: 0.3938\n",
      "Epoch 20/200\n",
      "186/186 [==============================] - 0s 414us/step - loss: 0.3943\n",
      "Epoch 21/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3923\n",
      "Epoch 22/200\n",
      "186/186 [==============================] - 0s 377us/step - loss: 0.3897\n",
      "Epoch 23/200\n",
      "186/186 [==============================] - 0s 406us/step - loss: 0.3909\n",
      "Epoch 24/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3913\n",
      "Epoch 25/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3937\n",
      "Epoch 26/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3891\n",
      "Epoch 27/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.3880\n",
      "Epoch 28/200\n",
      "186/186 [==============================] - 0s 331us/step - loss: 0.3892\n",
      "Epoch 29/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3883\n",
      "Epoch 30/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.3882\n",
      "Epoch 31/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.3870\n",
      "Epoch 32/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3872\n",
      "Epoch 33/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3898\n",
      "Epoch 34/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.3863\n",
      "Epoch 35/200\n",
      "186/186 [==============================] - 0s 334us/step - loss: 0.3852\n",
      "Epoch 36/200\n",
      "186/186 [==============================] - 0s 328us/step - loss: 0.3863\n",
      "Epoch 37/200\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.3832\n",
      "Epoch 38/200\n",
      "186/186 [==============================] - 0s 363us/step - loss: 0.3869\n",
      "Epoch 39/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.3910\n",
      "Epoch 40/200\n",
      "186/186 [==============================] - 0s 358us/step - loss: 0.3817\n",
      "Epoch 41/200\n",
      "186/186 [==============================] - 0s 320us/step - loss: 0.3854\n",
      "Epoch 42/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.3821\n",
      "Epoch 43/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3825\n",
      "Epoch 44/200\n",
      "186/186 [==============================] - 0s 441us/step - loss: 0.3804\n",
      "Epoch 45/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.3809\n",
      "Epoch 46/200\n",
      "186/186 [==============================] - 0s 441us/step - loss: 0.3818\n",
      "Epoch 47/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.3791\n",
      "Epoch 48/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3789\n",
      "Epoch 49/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.3777\n",
      "Epoch 50/200\n",
      "186/186 [==============================] - 0s 328us/step - loss: 0.3771\n",
      "Epoch 51/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3796\n",
      "Epoch 52/200\n",
      "186/186 [==============================] - 0s 336us/step - loss: 0.3761\n",
      "Epoch 53/200\n",
      "186/186 [==============================] - 0s 363us/step - loss: 0.3778\n",
      "Epoch 54/200\n",
      "186/186 [==============================] - 0s 336us/step - loss: 0.3753\n",
      "Epoch 55/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3745\n",
      "Epoch 56/200\n",
      "186/186 [==============================] - 0s 344us/step - loss: 0.3772\n",
      "Epoch 57/200\n",
      "186/186 [==============================] - 0s 323us/step - loss: 0.3729\n",
      "Epoch 58/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.3735\n",
      "Epoch 59/200\n",
      "186/186 [==============================] - 0s 377us/step - loss: 0.3732\n",
      "Epoch 60/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.3736\n",
      "Epoch 61/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3704\n",
      "Epoch 62/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.3733\n",
      "Epoch 63/200\n",
      "186/186 [==============================] - 0s 395us/step - loss: 0.3778\n",
      "Epoch 64/200\n",
      "186/186 [==============================] - 0s 336us/step - loss: 0.3694\n",
      "Epoch 65/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.3770\n",
      "Epoch 66/200\n",
      "186/186 [==============================] - 0s 328us/step - loss: 0.3685\n",
      "Epoch 67/200\n",
      "186/186 [==============================] - 0s 395us/step - loss: 0.3817\n",
      "Epoch 68/200\n",
      "186/186 [==============================] - 0s 342us/step - loss: 0.3644\n",
      "Epoch 69/200\n",
      "186/186 [==============================] - 0s 414us/step - loss: 0.3772\n",
      "Epoch 70/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.3659\n",
      "Epoch 71/200\n",
      "186/186 [==============================] - 0s 334us/step - loss: 0.3672\n",
      "Epoch 72/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.3686\n",
      "Epoch 73/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3706\n",
      "Epoch 74/200\n",
      "186/186 [==============================] - 0s 347us/step - loss: 0.3741\n",
      "Epoch 75/200\n",
      "186/186 [==============================] - 0s 342us/step - loss: 0.3642\n",
      "Epoch 76/200\n",
      "186/186 [==============================] - 0s 490us/step - loss: 0.3641\n",
      "Epoch 77/200\n",
      "186/186 [==============================] - 0s 406us/step - loss: 0.3750\n",
      "Epoch 78/200\n",
      "186/186 [==============================] - 0s 398us/step - loss: 0.3673\n",
      "Epoch 79/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.3659\n",
      "Epoch 80/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.3632\n",
      "Epoch 81/200\n",
      "186/186 [==============================] - 0s 452us/step - loss: 0.3700\n",
      "Epoch 82/200\n",
      "186/186 [==============================] - 0s 347us/step - loss: 0.3626\n",
      "Epoch 83/200\n",
      "186/186 [==============================] - 0s 409us/step - loss: 0.3581\n",
      "Epoch 84/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3582\n",
      "Epoch 85/200\n",
      "186/186 [==============================] - 0s 382us/step - loss: 0.3547\n",
      "Epoch 86/200\n",
      "186/186 [==============================] - 0s 344us/step - loss: 0.3565\n",
      "Epoch 87/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3571\n",
      "Epoch 88/200\n",
      "186/186 [==============================] - 0s 412us/step - loss: 0.3589\n",
      "Epoch 89/200\n",
      "186/186 [==============================] - 0s 358us/step - loss: 0.3529\n",
      "Epoch 90/200\n",
      "186/186 [==============================] - 0s 347us/step - loss: 0.3573\n",
      "Epoch 91/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3530\n",
      "Epoch 92/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.3532\n",
      "Epoch 93/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3503\n",
      "Epoch 94/200\n",
      "186/186 [==============================] - 0s 447us/step - loss: 0.3494\n",
      "Epoch 95/200\n",
      "186/186 [==============================] - 0s 344us/step - loss: 0.3491\n",
      "Epoch 96/200\n",
      "186/186 [==============================] - 0s 438us/step - loss: 0.3481\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 406us/step - loss: 0.3496\n",
      "Epoch 98/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.3476\n",
      "Epoch 99/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3461\n",
      "Epoch 100/200\n",
      "186/186 [==============================] - 0s 441us/step - loss: 0.3486\n",
      "Epoch 101/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.3448\n",
      "Epoch 102/200\n",
      "186/186 [==============================] - 0s 363us/step - loss: 0.3453\n",
      "Epoch 103/200\n",
      "186/186 [==============================] - 0s 538us/step - loss: 0.3438\n",
      "Epoch 104/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3443\n",
      "Epoch 105/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.3458\n",
      "Epoch 106/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.3429\n",
      "Epoch 107/200\n",
      "186/186 [==============================] - 0s 409us/step - loss: 0.3396\n",
      "Epoch 108/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.3406\n",
      "Epoch 109/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3453\n",
      "Epoch 110/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.3380\n",
      "Epoch 111/200\n",
      "186/186 [==============================] - 0s 455us/step - loss: 0.3390\n",
      "Epoch 112/200\n",
      "186/186 [==============================] - 0s 409us/step - loss: 0.3373\n",
      "Epoch 113/200\n",
      "186/186 [==============================] - 0s 447us/step - loss: 0.3446\n",
      "Epoch 114/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.3360\n",
      "Epoch 115/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3354\n",
      "Epoch 116/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.3358\n",
      "Epoch 117/200\n",
      "186/186 [==============================] - 0s 382us/step - loss: 0.3333\n",
      "Epoch 118/200\n",
      "186/186 [==============================] - 0s 363us/step - loss: 0.3368\n",
      "Epoch 119/200\n",
      "186/186 [==============================] - 0s 452us/step - loss: 0.3330\n",
      "Epoch 120/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3334\n",
      "Epoch 121/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3364\n",
      "Epoch 122/200\n",
      "186/186 [==============================] - 0s 369us/step - loss: 0.3330\n",
      "Epoch 123/200\n",
      "186/186 [==============================] - 0s 414us/step - loss: 0.3282\n",
      "Epoch 124/200\n",
      "186/186 [==============================] - 0s 395us/step - loss: 0.3296\n",
      "Epoch 125/200\n",
      "186/186 [==============================] - 0s 447us/step - loss: 0.3288\n",
      "Epoch 126/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.3263\n",
      "Epoch 127/200\n",
      "186/186 [==============================] - 0s 377us/step - loss: 0.3264\n",
      "Epoch 128/200\n",
      "186/186 [==============================] - 0s 387us/step - loss: 0.3303\n",
      "Epoch 129/200\n",
      "186/186 [==============================] - 0s 355us/step - loss: 0.3264\n",
      "Epoch 130/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.3259\n",
      "Epoch 131/200\n",
      "186/186 [==============================] - 0s 463us/step - loss: 0.3251\n",
      "Epoch 132/200\n",
      "186/186 [==============================] - 0s 355us/step - loss: 0.3249\n",
      "Epoch 133/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.3211\n",
      "Epoch 134/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.3225\n",
      "Epoch 135/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.3207\n",
      "Epoch 136/200\n",
      "186/186 [==============================] - 0s 355us/step - loss: 0.3184\n",
      "Epoch 137/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.3266\n",
      "Epoch 138/200\n",
      "186/186 [==============================] - 0s 366us/step - loss: 0.3203\n",
      "Epoch 139/200\n",
      "186/186 [==============================] - 0s 344us/step - loss: 0.3263\n",
      "Epoch 140/200\n",
      "186/186 [==============================] - 0s 514us/step - loss: 0.3255\n",
      "Epoch 141/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.3199\n",
      "Epoch 142/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.3299\n",
      "Epoch 143/200\n",
      "186/186 [==============================] - 0s 377us/step - loss: 0.3310\n",
      "Epoch 144/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.3235\n",
      "Epoch 145/200\n",
      "186/186 [==============================] - 0s 430us/step - loss: 0.3116\n",
      "Epoch 146/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3132\n",
      "Epoch 147/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3254\n",
      "Epoch 148/200\n",
      "186/186 [==============================] - 0s 406us/step - loss: 0.3419\n",
      "Epoch 149/200\n",
      "186/186 [==============================] - 0s 355us/step - loss: 0.3154\n",
      "Epoch 150/200\n",
      "186/186 [==============================] - 0s 390us/step - loss: 0.3225\n",
      "Epoch 151/200\n",
      "186/186 [==============================] - 0s 406us/step - loss: 0.3246\n",
      "Epoch 152/200\n",
      "186/186 [==============================] - 0s 366us/step - loss: 0.3336\n",
      "Epoch 153/200\n",
      "186/186 [==============================] - 0s 352us/step - loss: 0.3071\n",
      "Epoch 154/200\n",
      "186/186 [==============================] - 0s 409us/step - loss: 0.3121\n",
      "Epoch 155/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.3118\n",
      "Epoch 156/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3067\n",
      "Epoch 157/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.3150\n",
      "Epoch 158/200\n",
      "186/186 [==============================] - 0s 374us/step - loss: 0.3075\n",
      "Epoch 159/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3167\n",
      "Epoch 160/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3596\n",
      "Epoch 161/200\n",
      "186/186 [==============================] - 0s 344us/step - loss: 0.3157\n",
      "Epoch 162/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.3109\n",
      "Epoch 163/200\n",
      "186/186 [==============================] - 0s 433us/step - loss: 0.3037\n",
      "Epoch 164/200\n",
      "186/186 [==============================] - 0s 460us/step - loss: 0.2991\n",
      "Epoch 165/200\n",
      "186/186 [==============================] - 0s 522us/step - loss: 0.3014\n",
      "Epoch 166/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.2986\n",
      "Epoch 167/200\n",
      "186/186 [==============================] - 0s 484us/step - loss: 0.3028\n",
      "Epoch 168/200\n",
      "186/186 [==============================] - 0s 449us/step - loss: 0.3015\n",
      "Epoch 169/200\n",
      "186/186 [==============================] - 0s 433us/step - loss: 0.2940\n",
      "Epoch 170/200\n",
      "186/186 [==============================] - 0s 457us/step - loss: 0.2935\n",
      "Epoch 171/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.2979\n",
      "Epoch 172/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.2975\n",
      "Epoch 173/200\n",
      "186/186 [==============================] - 0s 377us/step - loss: 0.2933\n",
      "Epoch 174/200\n",
      "186/186 [==============================] - 0s 382us/step - loss: 0.3014\n",
      "Epoch 175/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.3070\n",
      "Epoch 176/200\n",
      "186/186 [==============================] - 0s 401us/step - loss: 0.3065\n",
      "Epoch 177/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.2914\n",
      "Epoch 178/200\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.2865\n",
      "Epoch 179/200\n",
      "186/186 [==============================] - 0s 471us/step - loss: 0.2855\n",
      "Epoch 180/200\n",
      "186/186 [==============================] - 0s 441us/step - loss: 0.2846\n",
      "Epoch 181/200\n",
      "186/186 [==============================] - 0s 382us/step - loss: 0.2874\n",
      "Epoch 182/200\n",
      "186/186 [==============================] - 0s 350us/step - loss: 0.2819\n",
      "Epoch 183/200\n",
      "186/186 [==============================] - 0s 363us/step - loss: 0.2817\n",
      "Epoch 184/200\n",
      "186/186 [==============================] - 0s 379us/step - loss: 0.2818\n",
      "Epoch 185/200\n",
      "186/186 [==============================] - 0s 336us/step - loss: 0.2804\n",
      "Epoch 186/200\n",
      "186/186 [==============================] - 0s 339us/step - loss: 0.2809\n",
      "Epoch 187/200\n",
      "186/186 [==============================] - 0s 417us/step - loss: 0.2794\n",
      "Epoch 188/200\n",
      "186/186 [==============================] - 0s 326us/step - loss: 0.2773\n",
      "Epoch 189/200\n",
      "186/186 [==============================] - 0s 404us/step - loss: 0.2782\n",
      "Epoch 190/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.2801\n",
      "Epoch 191/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.2776\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 452us/step - loss: 0.2788\n",
      "Epoch 193/200\n",
      "186/186 [==============================] - 0s 436us/step - loss: 0.2707\n",
      "Epoch 194/200\n",
      "186/186 [==============================] - 0s 336us/step - loss: 0.2780\n",
      "Epoch 195/200\n",
      "186/186 [==============================] - 0s 371us/step - loss: 0.2830\n",
      "Epoch 196/200\n",
      "186/186 [==============================] - 0s 444us/step - loss: 0.2697\n",
      "Epoch 197/200\n",
      "186/186 [==============================] - 0s 422us/step - loss: 0.2707\n",
      "Epoch 198/200\n",
      "186/186 [==============================] - 0s 428us/step - loss: 0.2768\n",
      "Epoch 199/200\n",
      "186/186 [==============================] - 0s 385us/step - loss: 0.2772\n",
      "Epoch 200/200\n",
      "186/186 [==============================] - 0s 360us/step - loss: 0.2853\n"
     ]
    }
   ],
   "source": [
    "# Hay modelos ya guardados con anterioridad a los que podemos acceder más adelante por si no queremos repetir el proceso de \n",
    "# creación de la red neuronal con los diferentes archivos csv.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(200, input_shape = (1, periodo), activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(matrizDatosEntrenamiento, salidaEntrenamiento, epochs = 200)\n",
    "\n",
    "# Guardamos el modelo de la red neuronal.\n",
    "# Modelo entrenado con diez años de datos.\n",
    "# model.save('RedEntrenamiento(2007-2016).h5')\n",
    "\n",
    "# Modelo entrenado con dos años de datos.\n",
    "# model.save('RedEntrenamiento(2015-2016).h5')\n",
    "\n",
    "# Modelo entrenado con un año de datos.\n",
    "model.save('RedEntrenamiento(2016).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "31/31 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo que nos interesa.\n",
    "# Modelo entrenado con diez años de datos.\n",
    "# model = load_model('RedEntrenamiento(2007-2016).h5')\n",
    "\n",
    "# Modelo entrenado con dos años de datos.\n",
    "# model = load_model('RedEntrenamiento(2015-2016).h5')\n",
    "\n",
    "# Modelo entrenado con un año de datos.\n",
    "model = load_model('RedEntrenamiento(2016).h5')\n",
    "\n",
    "validacion = model.evaluate(matrizDatosEvaluate, salidaValidacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Dibujamos una representación del modelo y la gráfica del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 200)               176800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 177,001\n",
      "Trainable params: 177,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pintamos la gráfica del error para el conjunto entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20257d18470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Gráfica del error')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.legend(['Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Pruebas de predicciones cada cierto periodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el modelo de nuestra red si no estaba cargado de antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo que nos interesa.\n",
    "# Modelo entrenado con diez años de datos.\n",
    "# model = load_model('RedEntrenamiento(2007-2016).h5')\n",
    "\n",
    "# Modelo entrenado con dos años de datos.\n",
    "# model = load_model('RedEntrenamiento(2015-2016).h5')\n",
    "\n",
    "# Modelo entrenado con un año de datos.\n",
    "model = load_model('RedEntrenamiento(2016).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos una predicciones sobre las predicciones hechas con anterioridad, generando dinámicamente nuevos arrays que contengan las predicciones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para realizar las predicciones de los diferentes periodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecirPeriodo (inicio, fin, periodo, y):\n",
    "    \n",
    "    # Inicializamos un vector a ceros.\n",
    "    yPeriodo = np.zeros(periodo)\n",
    "    cont = 0\n",
    "    \n",
    "    # Con este for cogemos solo un periodo de las salidas de las cuales predeciremos el siguiente periodo.\n",
    "    for i in range (inicio, fin):\n",
    "        yPeriodo[cont] = y[i]\n",
    "        cont = cont + 1\n",
    "    \n",
    "    # Hacemos un reshape necesario para predecir con el modelo LSTM.\n",
    "    yPeriodo = np.reshape(yPeriodo, (1, 1, periodo))\n",
    "    \n",
    "    # Guardamos en prediccionPeriodo los valores de yPeriodo que poco a poco se irán cambiando por los valores predichos.\n",
    "    prediccionPeriodo = yPeriodo\n",
    "    datoPredicho = 0\n",
    "    \n",
    "    \n",
    "    for i in range (0, periodo):\n",
    "    \n",
    "        # Predecimos \n",
    "        datoPredicho = model.predict(prediccionPeriodo)\n",
    "        # En yPeriodo le metemos el nuevo dato predicho\n",
    "        yPeriodo = np.append(yPeriodo, datoPredicho)\n",
    "    \n",
    "        for j in range(0, periodo):\n",
    "            prediccionPeriodo[0][0][j] = yPeriodo[i + j + 1]\n",
    "    \n",
    "    \n",
    "    # Tenemos que hacer un reshape para poder luego usarlo en la gráfica.\n",
    "    prediccionPeriodo = np.reshape(prediccionPeriodo, (periodo))\n",
    "    \n",
    "    \n",
    "    cont=0\n",
    "    diasPrediccion = np.zeros((periodo))\n",
    "    for i in range (inicio, fin):\n",
    "        diasPrediccion[cont] = i\n",
    "        cont = cont + 1\n",
    "    \n",
    "\n",
    "    \n",
    "    return diasPrediccion, prediccionPeriodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos el archivo con el cual queremos predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2026378ec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargamos los datos.\n",
    "DatosPrediccion = pd.read_csv('GAS.MC.Prediccion(2017).csv')\n",
    "\n",
    "# Guardamos los datos de los precios de cierre en una variable\n",
    "y = DatosPrediccion['Close']\n",
    "# Pasamos el dataset a tipo float.\n",
    "y = y.astype(float)\n",
    "# Transformamos el dataset a un vector array.\n",
    "y = np.array(y)\n",
    "\n",
    "# Vamos a predecir para probar con doce periodos para obtener las predicciones de todo el año.\n",
    "# Aqui es donde realizaremos las llamadas a la función que creamos antes.\n",
    "# Primer periodo\n",
    "inicio = 0\n",
    "fin = periodo\n",
    "diasPrediccion1, yPrediccion1 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Segundo periodo\n",
    "inicio = periodo\n",
    "fin = periodo * 2\n",
    "diasPrediccion2, yPrediccion2 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Tercer periodo\n",
    "inicio = periodo * 2\n",
    "fin = periodo * 3\n",
    "diasPrediccion3, yPrediccion3 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Cuarto periodo\n",
    "inicio = periodo * 3\n",
    "fin = periodo * 4\n",
    "diasPrediccion4, yPrediccion4 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Quinto periodo\n",
    "inicio = periodo * 4\n",
    "fin = periodo * 5\n",
    "diasPrediccion5, yPrediccion5 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Sexto periodo\n",
    "inicio = periodo * 5\n",
    "fin = periodo * 6\n",
    "diasPrediccion6, yPrediccion6 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Septima periodo\n",
    "inicio = periodo * 6\n",
    "fin = periodo * 7\n",
    "diasPrediccion7, yPrediccion7 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Octavo periodo\n",
    "inicio = periodo * 7\n",
    "fin = periodo * 8\n",
    "diasPrediccion8, yPrediccion8 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Noveno periodo\n",
    "inicio = periodo * 8\n",
    "fin = periodo * 9\n",
    "diasPrediccion9, yPrediccion9 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Decimo periodo\n",
    "inicio = periodo * 9\n",
    "fin = periodo * 10\n",
    "diasPrediccion10, yPrediccion10 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Onceavo periodo\n",
    "inicio = periodo * 10\n",
    "fin = periodo * 11\n",
    "diasPrediccion11, yPrediccion11 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "# Doceavo periodo\n",
    "inicio = periodo * 11\n",
    "fin = periodo * 12\n",
    "diasPrediccion12, yPrediccion12 = predecirPeriodo (inicio, fin, periodo, y)\n",
    "\n",
    "\n",
    "# Para la gráfica \n",
    "Dias = len(y)\n",
    "NumDia = np.zeros((len(y)))\n",
    "SalidaGrafica = np.zeros((Dias))\n",
    "cont = 0\n",
    "for i in range (0, len(y)):\n",
    "    SalidaGrafica[cont] = y[i]\n",
    "    cont = cont +1\n",
    "    \n",
    "#print(SalidaGrafica)\n",
    "\n",
    "for i in range(0, len(SalidaGrafica)):\n",
    "    NumDia[i] = i\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(NumDia,SalidaGrafica, 'b')\n",
    "plt.plot(diasPrediccion1, yPrediccion1, 'r')\n",
    "plt.plot(diasPrediccion2, yPrediccion2, 'c')\n",
    "plt.plot(diasPrediccion3, yPrediccion3, 'y')\n",
    "plt.plot(diasPrediccion4, yPrediccion4, 'r')\n",
    "plt.plot(diasPrediccion5, yPrediccion5, 'c')\n",
    "plt.plot(diasPrediccion6, yPrediccion6, 'y')\n",
    "plt.plot(diasPrediccion7, yPrediccion7, 'r')\n",
    "plt.plot(diasPrediccion8, yPrediccion8, 'c')\n",
    "plt.plot(diasPrediccion9, yPrediccion9, 'y')\n",
    "plt.plot(diasPrediccion10, yPrediccion10, 'r')\n",
    "plt.plot(diasPrediccion11, yPrediccion11, 'c')\n",
    "plt.plot(diasPrediccion12, yPrediccion12, 'y')\n",
    "\n",
    "plt.xlabel('Día')\n",
    "plt.ylabel('Cierre')\n",
    "plt.title('Historico de datos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Calculamos el valor de los pesos de cada parámetro de nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la entrada 0 la suma de sus pesos es: 1.947409453738672\n",
      "Para la entrada 1 la suma de sus pesos es: 1.9633955664471796\n",
      "Para la entrada 2 la suma de sus pesos es: 1.849252471864884\n",
      "Para la entrada 3 la suma de sus pesos es: 1.92762944596843\n",
      "Para la entrada 4 la suma de sus pesos es: 2.0349128994484666\n",
      "Para la entrada 5 la suma de sus pesos es: 1.9584287682718937\n",
      "Para la entrada 6 la suma de sus pesos es: 1.8870672862909332\n",
      "Para la entrada 7 la suma de sus pesos es: 1.8983033322593057\n",
      "Para la entrada 8 la suma de sus pesos es: 1.913709916733496\n",
      "Para la entrada 9 la suma de sus pesos es: 1.9859710174139908\n",
      "Para la entrada 10 la suma de sus pesos es: 1.9062351342723352\n",
      "Para la entrada 11 la suma de sus pesos es: 2.002986954094112\n",
      "Para la entrada 12 la suma de sus pesos es: 1.8798267347773\n",
      "Para la entrada 13 la suma de sus pesos es: 2.0091275872666543\n",
      "Para la entrada 14 la suma de sus pesos es: 2.0457864701811914\n",
      "Para la entrada 15 la suma de sus pesos es: 2.0632582719836154\n",
      "Para la entrada 16 la suma de sus pesos es: 2.051935263039134\n",
      "Para la entrada 17 la suma de sus pesos es: 2.034789365527523\n",
      "Para la entrada 18 la suma de sus pesos es: 2.0732521645651607\n",
      "Para la entrada 19 la suma de sus pesos es: 1.9670614730521248\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, periodo):\n",
    "    print(\"Para la entrada\", i, \"la suma de sus pesos es:\", sum((model.get_weights()[0][i])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
